{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecaafc1b",
   "metadata": {},
   "source": [
    "# MALIGNANT COMMENTS CLASSIFICATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52d52d",
   "metadata": {},
   "source": [
    "Data Set Description The data set contains the training set, which has approximately 1,59,000 samples and the test set which contains nearly 1,53,000 samples. All the data samples contain 8 fields which includes ‘Id’, ‘Comments’, ‘Malignant’, ‘Highly malignant’, ‘Rude’, ‘Threat’, ‘Abuse’ and ‘Loathe’.\n",
    "The label can be either 0 or 1, where 0 denotes a NO while 1 denotes a YES. There are various comments which have multiple labels. The first attribute is a unique ID associated with each comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad282f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all required libraries for the project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy as stats\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import wordnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a17f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import train csv file to jupyter notebook\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cdd2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import test csv file to jupyter notebook\n",
    "df_test=pd.read_csv(\"test.csv\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd704cf",
   "metadata": {},
   "source": [
    "# EDA(Exploratory Data Analysis) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb1b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the names of the columns present in the train dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1b61e",
   "metadata": {},
   "source": [
    "  - Here we can see all the names of the columns present in our train dataset with Malignant as our target column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f031fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the names of the columns present in the test dataset\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c17d0",
   "metadata": {},
   "source": [
    "  - Here we can see the names of the columns present in our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check shape of the train dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9d7a6",
   "metadata": {},
   "source": [
    "  - Here we can see that there are 1,59,571 rows present in 8 columns of train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6385d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the shape of the test dataset\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db2b1e",
   "metadata": {},
   "source": [
    "  - Here we can see that there are 1,53,164 rows present in 2 columns of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08114091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the information about the train dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4fb5a",
   "metadata": {},
   "source": [
    "  - Here we can see that there are no Null values present in our train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1dca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the information regarding the test dataset\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022acc06",
   "metadata": {},
   "source": [
    "  - Here we can see that there are no null values present in the test dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454368e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the value counts of all the columns in the train dataset\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc8c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['malignant'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fbd117",
   "metadata": {},
   "source": [
    "  - Here 0 denotes No and 1 denotes Yes. so most of the messages are not Malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['highly_malignant'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af89d39",
   "metadata": {},
   "source": [
    "  - Here also we can see very few messages are Highly Malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rude'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58247cf1",
   "metadata": {},
   "source": [
    "  - Few of the messages are rude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddc5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['threat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388815fe",
   "metadata": {},
   "source": [
    "  - Here we can see very few messages have threat content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c9e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abuse'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad47bc5",
   "metadata": {},
   "source": [
    "  - Here we can see few messages have abusive language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dfc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loathe'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c8a9e",
   "metadata": {},
   "source": [
    "  - Here we can see that there are few messages have loathe or disgusting language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the datatype of all the columns present in the train dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad28b12f",
   "metadata": {},
   "source": [
    "  - Here we can see that there are two types of dtype present in the train dataset i.e. object and integer dtype.\n",
    "  - Here we can see that there is 1st column name id, id's are unique for all the comments dataset and it wont help in our model building, it will make the model more complex and less accurate. so, we must drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa10253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop the column id from train dataset\n",
    "df.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ca4d6",
   "metadata": {},
   "source": [
    "  - Here we have successfully dropped the column id from our train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4123441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the presence of null value once again in train dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55422cd",
   "metadata": {},
   "source": [
    "  - Here we are again confirmed that there are no null values present in this train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e056f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check few comments present in the train dataset\n",
    "df['comment_text'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_text'][27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89797e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b2420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_text'][117]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed8899b",
   "metadata": {},
   "source": [
    "  - Here after observing some comments, We can clearly see that there is a need of text processing as there are many numbers, alphabets and special characters present in the comments which are not important or required for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a new column showing length of words in comment_text in train dataset\n",
    "df['before_clean']=df['comment_text'].map(lambda comment_text: len(comment_text))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81921aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a new column named before clean showing no. of words present in comment_text column in test dataset\n",
    "df_test['before_clean']=df_test['comment_text'].map(lambda comment_text: len(comment_text))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28bcecc",
   "metadata": {},
   "source": [
    "# Text Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets download latest updated stopwords and wordnet.\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273de778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')\n",
    "lemmatizer=wordnet.WordNetLemmatizer()\n",
    "# lets clean the messages and remove or replace some words\n",
    "def edited(text):\n",
    "    #convert to lower case\n",
    "    lowered_text = text.lower()\n",
    "    \n",
    "    #Replacing email addresses with 'emailaddress'\n",
    "    text = re.sub(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress', lowered_text)\n",
    "    \n",
    "    #Replace URLs with 'webaddress'\n",
    "    text = re.sub(r'http\\S+', 'webaddress', text)\n",
    "    \n",
    "    #Removing numbers\n",
    "    text = re.sub(r'[0-9]', \" \", text)\n",
    "    \n",
    "    #Removing the HTML tags\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    \n",
    "    #Removing Punctuations\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\_',' ',text)\n",
    "    \n",
    "    #Removing all the non-ascii characters \n",
    "    clean_words = re.sub(r'[^\\x00-\\x7f]',r'', text)\n",
    "    \n",
    "    #Removing the unwanted white spaces\n",
    "    text = \" \".join(text.split()) \n",
    "    \n",
    "    # lets remove '\\n' in comment_text\n",
    "    text= re.sub(r'\\n',' ',text)\n",
    "    \n",
    "    #Splitting data into words\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    \n",
    "    #Removing remaining tokens that are not alphabetic, Removing stop words and Lemmatizing the text\n",
    "    removed_stop_text = [lemmatizer.lemmatize(word) for word in tokenized_text if word not in stop_words if word.isalpha()]\n",
    "   \n",
    "    return \" \".join(removed_stop_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd79d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the above function for the column comment_text in training dataset to replace original with cleaned text\n",
    "df['comment_text'] = df['comment_text'].apply(edited)\n",
    "df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d39c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column 'len_after_cleaning'\n",
    "#Representing the length of the each comment respectively in a column 'comment_text' after cleaning the text.\n",
    "df['len_after_cleaning'] = df['comment_text'].map(lambda comment_text: len(comment_text))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import wordcloud to jupyter notebook\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordcloud\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52eed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wcloud(df, label):\n",
    "    \n",
    "    # lets print only rows where the label value is 1 (ie. where comment is harsh)\n",
    "    subset=df[df[label]==1]\n",
    "    text=subset.comment_text.values\n",
    "    wc= WordCloud(background_color=\"black\",max_words=4500)\n",
    "\n",
    "    wc.generate(\" \".join(text))\n",
    "\n",
    "    plt.figure(figsize=(27,27))\n",
    "    plt.subplot(221)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Words frequented in {}\".format(label), fontsize=18)\n",
    "    plt.imshow(wc.recolor(colormap= 'gist_earth' , random_state=244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb80aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m=df.loc[:,['comment_text','malignant']]\n",
    "wcloud(df_m,'malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654bc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hm=df.loc[:,['comment_text','highly_malignant']]\n",
    "wcloud(df_hm,'highly_malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ece63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r=df.loc[:,['comment_text','rude']]\n",
    "wcloud(df_r,'rude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abac8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t=df.loc[:,['comment_text','threat']]\n",
    "wcloud(df_t,'threat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a=df.loc[:,['comment_text','abuse']]\n",
    "wcloud(df_a,'abuse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l=df.loc[:,['comment_text','loathe']]\n",
    "wcloud(df_l,'loathe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d219113",
   "metadata": {},
   "source": [
    "# Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a47453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot all features using countplot\n",
    "feat=df.columns[1:]\n",
    "for col in feat:\n",
    "    sns.countplot(df[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c253e76",
   "metadata": {},
   "source": [
    "  - Here in the first graph of malignant we can clearly observe that most of the messages are not malignant.\n",
    "  - In the second image we can clearly observe that there are very less highly malignant messages.\n",
    "  - Same in third picture there are few rude comments in the dataset.\n",
    "  - In 4th we can clearly see that there are very few cases/almost negligible of threat comments\n",
    "  - In 5th image we can clearly see that there are some messages with abusive language.\n",
    "  - While in the sixth image we can clearly see that there are very few cases of loathe messages.\n",
    "  - In 7th image we can see the no. of words in each rows\n",
    "  - In 8th image we can see the cleaned no. of remaining words in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152db19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a list of feature columns\n",
    "featu=['malignant','highly_malignant','rude','threat','abuse','loathe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13322ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets store the no. of counts for every target\n",
    "counts=df[featu].iloc[:,0:].sum()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot and visualize count of each columns\n",
    "plt.figure(figsize=(18,9))\n",
    "ax=sns.barplot(counts.index,counts.values)\n",
    "plt.title(\"Total no. of messages in each columns\")\n",
    "plt.ylabel('Freq', fontsize=9)\n",
    "plt.xlabel('Columns',fontsize=9)\n",
    "rects=ax.patches\n",
    "labels=counts.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height=rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center',va='bottom' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebad16f",
   "metadata": {},
   "source": [
    "  - Here we can clearly see that maximum no. of messages were sent in malignant messages category, followed by rude and abuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the distribution of data using distplot\n",
    "for col in df[featu].describe().columns:\n",
    "    sns.distplot(df[featu][col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cda8b5",
   "metadata": {},
   "source": [
    "  - Here we can see data is skewed towards the right in all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43179c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the statistical description of all the columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ffbd9",
   "metadata": {},
   "source": [
    "  - Here we can see that only 2 values are present in all the columns i.e. 0 and 1.\n",
    "  - Low score of standard devaiation tells us that the data is not spreaded.\n",
    "  - there is difference in mean and median which tells us that some skewness is present.\n",
    "  - very low difference in 75% and max shows that there are no outliers present in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the correlation amoung all the columns \n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41434ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets visualize correlation using heatmap\n",
    "plt.figure(figsize=(9,8))\n",
    "sns.heatmap(df.corr(),linewidth=0.5, linecolor='black',fmt='.0%',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d244f8",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00937cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create label column in train dataset\n",
    "c_label= ['malignant','highly_malignant','rude','threat','abuse','loathe']\n",
    "df[c_label].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=df[c_label].sum(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e510d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets Check the count of labels\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(df['label'], palette='coolwarm')\n",
    "plt.title('Counting the labels',fontsize=27)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d49b14",
   "metadata": {},
   "source": [
    "# Model building:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f085396",
   "metadata": {},
   "source": [
    "## Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cd849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert text data using TfidfVectorizer\n",
    "# lets import library for vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "tfidf=TfidfVectorizer(max_features = 14000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149eb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Separate the input and output variables represented by X and y respectively in train data and convert them\n",
    "X = tfidf.fit_transform(df['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first convert features into number vectors\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7cae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the shape of the dataset\n",
    "print(X.shape,'\\t\\t',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e686ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the above process for test data \n",
    "test_vec = tfidf.fit_transform(df_test['comment_text'])\n",
    "test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9219b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "exclamation = []\n",
    "question = []\n",
    "\n",
    "for i in df.length:\n",
    "   length.append([i])\n",
    "for i in df.exclamation:\n",
    "   exclamation.append([i])\n",
    "for i in df.question:\n",
    "   question.append([i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0721e4d5",
   "metadata": {},
   "source": [
    "# Building the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14525766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the training and testing data \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74039c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of x data\n",
    "print(x_train.shape,'\\t\\t',x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9613edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of y data\n",
    "print(y_train.shape,'\\t',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9005f8",
   "metadata": {},
   "source": [
    "# Model Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a507fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.metrics import f1_score,precision_score, multilabel_confusion_matrix, accuracy_score,jaccard_score, recall_score, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b6f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the instance of the model\n",
    "svc = LinearSVC()\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "mnb = MultinomialNB()\n",
    "lgb = LGBMClassifier()\n",
    "sgd = SGDClassifier()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60140d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(y_pred,clf):\n",
    "    print('classifier:',clf.__class__.__name__)\n",
    "    print(\"Jaccard score: {}\".format(jaccard_score(y_test,y_pred,average='micro')))\n",
    "    print(\"Accuracy score: {}\".format(accuracy_score(y_test,y_pred)))\n",
    "    print(\"f1_score: {}\".format(f1_score(y_test,y_pred,average='micro')))\n",
    "    print(\"Precision : \", precision_score(y_test,y_pred,average='micro'))\n",
    "    print(\"Recall: {}\".format(recall_score(y_test,y_pred,average='micro')))\n",
    "    print(\"Hamming loss: \", hamming_loss(y_test,y_pred))\n",
    "    print(\"Confusion matrix:\\n \", multilabel_confusion_matrix(y_test,y_pred))\n",
    "    print('========================================\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b38ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models with evaluation using OneVsRestClassifier\n",
    "for classifier in [svc,lr,mnb,sgd,lgb,rf]:\n",
    "   clf = OneVsRestClassifier(classifier)\n",
    "   clf.fit(x_train,y_train)\n",
    "   y_pred = clf.predict(x_test)\n",
    "   print_score(y_pred, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae048c32",
   "metadata": {},
   "source": [
    "  - we have got LinearSVC as our best model, so we will perform hyper parameter tuning on LinearSVC and try to increase its accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69000061",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating parameter list to pass in GridSearchCV\n",
    "param = {\n",
    "        'estimator__penalty': ['l1'],\n",
    "        'estimator__loss': ['hinge','squared_hinge'],\n",
    "        'estimator__multi_class': ['ovr','crammer_singer'],\n",
    "        'estimator__dual': [False],\n",
    "        'estimator__intercept_scaling': [2,4,5],\n",
    "        'estimator__C': [2]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56102cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "svc = OneVsRestClassifier(LinearSVC())\n",
    "GCV =  GridSearchCV(svc,param,cv = 3, verbose =0,n_jobs=-1)\n",
    "GCV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b466b",
   "metadata": {},
   "source": [
    "# Final Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(LinearSVC(C=2,dual = False, loss='hinge',multi_class='crammer_singer', penalty ='l1',intercept_scaling=2))\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"Jaccard score: {}\".format(jaccard_score(y_test,y_pred,average='micro')))\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"f1_score: {}\".format(f1_score(y_test,y_pred,average='micro')))\n",
    "print(\"Precision : \", precision_score(y_test,y_pred,average='micro'))\n",
    "print(\"Recall: {}\".format(recall_score(y_test,y_pred,average='micro')))\n",
    "print(\"Hamming loss: \", hamming_loss(y_test,y_pred))\n",
    "print(\"\\nConfusion matrix: \\n\", multilabel_confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5bc696",
   "metadata": {},
   "source": [
    "  - Here we have successfully improved slightly prediction score from 91.76 to 91.77%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_prediction=model.predict(X)\n",
    "#Making a dataframe of predictions\n",
    "malignant_prediction=pd.DataFrame({'Predictions':lsvc_prediction})\n",
    "malignant_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4036559a",
   "metadata": {},
   "source": [
    "# Saving Our Best Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c49fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "import pickle\n",
    "filename='MalignantCommentsClassifier.pkl'\n",
    "pickle.dump(model,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking our vectorized test data\n",
    "test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "fitted_model=pickle.load(open('MalignantCommentsClassifier.pkl','rb'))\n",
    "fitted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e85a4",
   "metadata": {},
   "source": [
    "# Prediction using test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98978b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test predictions\n",
    "test_results=pd.DataFrame(test_df)\n",
    "test_results.to_csv('Malignant_TestDataPredictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train predictions\n",
    "malignant_prediction.to_csv('Malignant_TrainDataPredictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets load the test data set\n",
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f79e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets load the test data set\n",
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1369b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "test_prediction=model.predict(test_vec)\n",
    "test_df=pd.DataFrame({'Predictions':test_prediction})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save the predictions\n",
    "test_results=pd.DataFrame(test_df)\n",
    "test_results.to_csv('Malignant_TestDataPredictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70333714",
   "metadata": {},
   "source": [
    "# saving the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_prediction.to_csv('Malignant_DataPredictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9243d53",
   "metadata": {},
   "source": [
    "  - Finally, we had predicted over the test data and the predictions obtained were saved in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa78d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c381271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde50d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e76a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce547666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef0985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6721ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e2ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba43e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c13b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
